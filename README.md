
# ğŸ™ï¸ VAANI - Voice Assistant for Android

A comprehensive voice-controlled Android assistant that converts natural speech into actionable commands on your mobile device.

## What Is It?

VAANI is an advanced Android voice assistant that combines cutting-edge speech recognition, natural language understanding, and dialogue management to provide seamless hands-free control of your smartphone. Simply speak commands and they execute instantly on your device.

**Key Capability**: Say "Open WhatsApp" â†’ WhatsApp opens. Say "What's the weather?" â†’ Get the weather forecast.

## Project Structure

```
vaani_voice_app/
â”œâ”€â”€ app/src/main/
â”‚   â”œâ”€â”€ java/com/vaani/voice/MainActivity.kt
â”‚   â”œâ”€â”€ res/layout/activity_main.xml
â”‚   â””â”€â”€ AndroidManifest.xml
â”œâ”€â”€ build.gradle
â””â”€â”€ settings.gradle
```

## How It Works

Speech Recognition â†’ Intent Match â†’ Execute Action

## Commands

- "Open WhatsApp"
- "Open Chrome"
- "Open Gmail"
- "Open YouTube"
- "Go home"

## Built With

- Kotlin
- Android SDK
- SpeechRecognizer API
- TextToSpeech API

## License

MIT

**Or with Python:**
```bash
python run_vaani_mobile.py --platform android --mode adb
```

This enables:
- âœ… Wake word activation ("Hey VAANI")
- âœ… Complete hands-free phone control
- âœ… Open apps, make calls, send messages by voice
- âœ… Read screen and notifications aloud
- âœ… Tap, swipe, scroll by voice commands
- âœ… Emergency SOS without touching phone
- âœ… Designed for elderly and disabled users

**See [Mobile Accessibility Guide](docs/MOBILE_ACCESSIBILITY_GUIDE.md) for full details.**

**No text input required - just speak naturally!**

## ğŸ—ï¸ Architecture

VAANI consists of seven core components:

```
User Speech â†’ VAD â†’ ASR â†’ NLU â†’ DST â†’ DM â†’ NLG â†’ TTS â†’ Audio Response
```

### Components

1. **VAD (Voice Activity Detection)**: Detects when the user is speaking
   - Technology: Silero VAD
   
2. **ASR (Automatic Speech Recognition)**: Converts speech to text
   - Phase 1: Google Speech API
   - Phase 2: Fine-tuned Whisper model
   
3. **NLU (Natural Language Understanding)**: Extracts intent and entities
   - Intent classification
   - Named entity recognition
   - Custom trained models
   
4. **DST (Dialogue State Tracking)**: Maintains conversation context
   - Tracks conversation history
   - Manages multi-turn dialogues
   
5. **DM (Dialogue Manager)**: Decides what action to take
   - Rule-based and ML-based decision making
   - Action execution
   
6. **NLG (Natural Language Generation)**: Generates text responses
   - Template-based responses
   - Dynamic response generation
   
7. **TTS (Text-to-Speech)**: Converts text to speech
   - Android native TTS
   - Custom voice options

## ğŸ¯ Supported Intents

VAANI currently supports 10 core intents:

| Intent | Description | Example |
|--------|-------------|---------|
| GREETING | Greet the assistant | "Hello VAANI" |
| QUERY_TIME | Ask for current time | "What time is it?" |
| QUERY_WEATHER | Get weather information | "What's the weather in Delhi?" |
| OPEN_APP | Launch applications | "Open YouTube" |
| CALL_PERSON | Make phone calls | "Call Mom" |
| GENERAL_KNOWLEDGE | Ask factual questions | "Who is Einstein?" |
| ALARM_SET | Set alarms | "Set alarm for 6 AM" |
| REMINDER_SET | Create reminders | "Remind me to buy milk" |
| JOKE | Request entertainment | "Tell me a joke" |
| CASUAL_CHAT | General conversation | "How are you?" |

## ğŸ“ Project Structure

```
vaani/
â”œâ”€â”€ data/                    # All datasets
â”‚   â”œâ”€â”€ audio_raw/          # Raw audio files
â”‚   â”œâ”€â”€ transcripts/        # Transcriptions
â”‚   â”œâ”€â”€ queries/            # Text queries
â”‚   â””â”€â”€ annotations/        # Labeled data
â”œâ”€â”€ models/                 # Trained models
â”‚   â”œâ”€â”€ asr/               # ASR models
â”‚   â”œâ”€â”€ nlu/               # NLU models
â”‚   â”œâ”€â”€ dst/               # DST models
â”‚   â””â”€â”€ dm/                # DM models
â”œâ”€â”€ pipeline/              # Core pipeline code
â”‚   â”œâ”€â”€ asr/              # ASR implementation
â”‚   â”œâ”€â”€ nlu/              # NLU implementation
â”‚   â”œâ”€â”€ dst/              # DST implementation
â”‚   â”œâ”€â”€ dm/               # DM implementation
â”‚   â”œâ”€â”€ nlg/              # NLG implementation
â”‚   â”œâ”€â”€ tts/              # TTS implementation
â”‚   â””â”€â”€ vad/              # VAD implementation
â”œâ”€â”€ app/                   # Application code
â”‚   â””â”€â”€ android/          # Android app
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ tests/                # Unit tests
â””â”€â”€ logs/                 # Application logs
```

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/vaani.git
cd vaani
```

### 2. Set Up Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Auto-repair audio environment
python scripts/fix_audio_env.py

# Test microphone
python scripts/test_microphone.py
```

### 3. Generate Initial Dataset

```bash
# Create project structure
python setup_structure.py

# Generate 1,000 sample queries
python generate_queries.py

# Generate synthetic audio (optional)
python generate_audio.py --engine gtts --limit 10
```

### 4. Train NLU Models

```bash
# Train intent classifier
python pipeline/nlu/train_intents.py --data data/queries/queries_day1.csv

# Train entity extractor (requires annotations)
python pipeline/nlu/train_entities.py --annotations data/annotations/sample_annotations.json
```

### 5. Run the CLI Demo

```bash
# Advanced streaming demo with Whisper + VAD
python cli/vaani_demo.py

# Or use the basic voice CLI
python cli/vaani_voice_cli.py

# Commands in demo:
#   start   - Start streaming mode with real-time ASR
#   stop    - Stop streaming
#   whisper - Toggle Whisper ASR
#   vad     - Toggle Voice Activity Detection
#   status  - Show system status
#   exit    - Exit
```

### 6. Explore the Data

```bash
# View generated queries
head data/queries/queries_day1.csv

# Check audio files (if generated)
ls data/audio_raw/day1/
```

## ğŸ® Advanced Demo (NEW!)

Experience the complete VAANI pipeline with our advanced demo system!

### Interactive CLI v2

Run the enhanced interactive CLI with full pipeline visualization:

```bash
python cli/vaani_cli_v2.py
```

**Features:**
- ğŸ¤ **Voice Input**: Record from microphone with `talk` command
- ğŸ“ **Audio Files**: Process WAV files with `audio <filepath>`
- ğŸ’¬ **Text Input**: Process text with `text "<message>"`
- ğŸ“Š **State Tracking**: View dialogue state with `state`
- ğŸ“œ **History**: See conversation history with `history`
- ğŸ”„ **Reset**: Clear state with `reset`

**Example Session:**
```
VAANI> text "hello VAANI"
ğŸ’¬ Response: Hello! How can I help you today?

VAANI> text "what's the weather in Delhi"
ğŸ’¬ Response: I'll check the weather in Delhi for you.

VAANI> state
Current Dialogue State:
  Turn Count: 2
  Active Intent: QUERY_WEATHER
  Stored Entities: 1
    - LOCATION: Delhi
```

### Advanced Pipeline Script

Process inputs with detailed stage-by-stage output:

```bash
# Process text
python pipeline/run_pipeline_advanced.py --text "what time is it"

# Process audio file
python pipeline/run_pipeline_advanced.py --audio samples/weather_delhi.wav

# Record from microphone
python pipeline/run_pipeline_advanced.py --microphone --duration 5

# Enable TTS output
python pipeline/run_pipeline_advanced.py --text "hello" --speak
```

**Pipeline Stages Shown:**
1. ğŸ”Š **VAD** - Voice Activity Detection
2. ğŸ“ **ASR** - Speech Recognition (Whisper â†’ Google â†’ Simulated)
3. ğŸ§  **NLU** - Intent & Entity Extraction
4. ğŸ’¾ **DST** - Dialogue State Update
5. ğŸ¯ **DM** - Action Decision
6. ğŸ’¬ **NLG** - Response Generation

**With colored output and timing for each stage!**

### Sample Audio Files

Generate sample audio files for testing:

```bash
# Install TTS dependencies
pip install gtts pydub

# Generate samples
python generate_sample_audio.py
```

This creates 8 sample WAV files in `samples/` directory covering all major intents.

### Complete Demo Guide

For detailed instructions, examples, and troubleshooting:

ğŸ“– **[Read the Complete Demo Guide](docs/DEMO_GUIDE.md)**

Includes:
- Prerequisites and setup
- Usage examples with expected output
- CLI commands reference
- Pipeline stages explained
- Troubleshooting guide
- Advanced features

## ğŸ› ï¸ Technology Stack

- **Language**: Python 3.8+
- **ML Frameworks**: PyTorch, Transformers, scikit-learn
- **ASR**: Google Speech API, OpenAI Whisper
- **NLP**: NLTK, spaCy
- **Audio Processing**: librosa, soundfile, pydub
- **TTS**: gTTS, pyttsx3, Coqui TTS
- **Mobile**: Android (Java/Kotlin)
- **Tools**: Jupyter, pytest, black, flake8

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

